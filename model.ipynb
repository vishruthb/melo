{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tuiYlqHCVXY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b27fe831-7924-4df1-f4fc-b29c22e08d95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet torch torchvision pandas scikit-learn pillow tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0orVu-uFYjBL",
        "outputId": "45f807bd-9a45-4fea-e042-7b3c01c462e3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "08Bslw50ZP_8",
        "outputId": "52a298a1-942c-4342-aaec-eaf57ef78d9f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-263b92f3-cfe5-428b-820b-54309c6aecb0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-263b92f3-cfe5-428b-820b-54309c6aecb0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"vishruthbharath\",\"key\":\"f27c8b108dae01498970cf312cffe7ca\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.dataset"
      ],
      "metadata": {
        "id": "37q2LqMueEGK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp kaggle.json ~/.dataset/"
      ],
      "metadata": {
        "id": "MWzgeejMeE9H"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.dataset/kaggle.json"
      ],
      "metadata": {
        "id": "603ji5eoeHVy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"kmader/skin-cancer-mnist-ham10000\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "np8hpGMBet2Z",
        "outputId": "c84563fa-8996-403f-839f-0e2af2d92ddb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/skin-cancer-mnist-ham10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataset.py\n",
        "# dataset.py – points to Kaggle’s read-only mount\n",
        "import pathlib, pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torchvision.transforms as T\n",
        "\n",
        "KAGGLE_DIR = pathlib.Path(\"/kaggle/input/skin-cancer-mnist-ham10000\")\n",
        "IMG_DIR = KAGGLE_DIR if KAGGLE_DIR.exists() else pathlib.Path(__file__).parent / \"dataset\"\n",
        "\n",
        "class HAMDataset(Dataset):\n",
        "    def __init__(self, df, tfms):\n",
        "        self.df, self.tfms = df.reset_index(drop=True), tfms\n",
        "    def __len__(self):  return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.df.iloc[idx]\n",
        "        img = Image.open(IMG_DIR / r.image_rel_path).convert(\"RGB\")\n",
        "        return self.tfms(img), int(r.label)\n",
        "\n",
        "def build_dataloaders(batch=32, val_split=0.15, seed=42, workers=2):\n",
        "    meta = pd.read_csv(IMG_DIR / \"HAM10000_metadata.csv\")\n",
        "    meta[\"image_rel_path\"] = meta[\"image_id\"].apply(\n",
        "        lambda iid: f\"HAM10000_images_part_1/{iid}.jpg\"\n",
        "        if (IMG_DIR / \"HAM10000_images_part_1\" / f\"{iid}.jpg\").exists()\n",
        "        else f\"HAM10000_images_part_2/{iid}.jpg\"\n",
        "    )\n",
        "    label2idx = {d:i for i,d in enumerate(sorted(meta.dx.unique()))}\n",
        "    meta[\"label\"] = meta.dx.map(label2idx)\n",
        "\n",
        "    train_df, val_df = train_test_split(meta, stratify=meta.label,\n",
        "                                        test_size=val_split, random_state=seed)\n",
        "\n",
        "    tfms = T.Compose([\n",
        "        T.Resize((224,224)),\n",
        "        T.RandomHorizontalFlip(),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize([0.5]*3, [0.5]*3)\n",
        "    ])\n",
        "    train_ds, val_ds = HAMDataset(train_df, tfms), HAMDataset(val_df, tfms)\n",
        "\n",
        "    # weighted sampler to handle class imbalance\n",
        "    counts = train_df.label.value_counts().sort_index().values\n",
        "    weights = 1. / torch.tensor(counts, dtype=torch.float)\n",
        "    samp_w  = weights[train_df.label.values]\n",
        "    sampler = WeightedRandomSampler(samp_w, len(samp_w), replacement=True)\n",
        "\n",
        "    train_dl = DataLoader(train_ds, batch_size=batch, sampler=sampler,\n",
        "                          num_workers=workers, pin_memory=True)\n",
        "    val_dl   = DataLoader(val_ds,   batch_size=batch, shuffle=False,\n",
        "                          num_workers=workers, pin_memory=True)\n",
        "    return train_dl, val_dl, label2idx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWAinfmZf6Lt",
        "outputId": "04456b73-48fb-44c4-9ee8-b421919cb334"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "# train.py – uses dataset.py\n",
        "import argparse, torch, torch.nn as nn, torchvision.models as models\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from tqdm import tqdm\n",
        "from dataset import build_dataloaders\n",
        "\n",
        "def train_epoch(model, dl, loss_fn, opt, device):\n",
        "    model.train(); run = 0.\n",
        "    for x,y in tqdm(dl, leave=False):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        opt.zero_grad()\n",
        "        loss = loss_fn(model(x), y)\n",
        "        loss.backward(); opt.step()\n",
        "        run += loss.item()*x.size(0)\n",
        "    return run / len(dl.dataset)\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch(model, dl, loss_fn, device):\n",
        "    model.eval(); run, correct = 0., 0\n",
        "    for x,y in dl:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        out  = model(x)\n",
        "        run += loss_fn(out,y).item()*x.size(0)\n",
        "        correct += (out.argmax(1)==y).sum().item()\n",
        "    return run/len(dl.dataset), correct/len(dl.dataset)\n",
        "\n",
        "def main(epochs, bs, lr):\n",
        "    train_dl, val_dl, label2idx = build_dataloaders(batch=bs, workers=2)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(label2idx))\n",
        "    model.to(device)\n",
        "\n",
        "    loss_fn, opt = nn.CrossEntropyLoss(), torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    sched = CosineAnnealingLR(opt, T_max=epochs)\n",
        "\n",
        "    best = 0.\n",
        "    for ep in range(1, epochs+1):\n",
        "        tr = train_epoch(model, train_dl, loss_fn, opt, device)\n",
        "        vl, acc = eval_epoch(model, val_dl, loss_fn, device)\n",
        "        sched.step()\n",
        "        print(f\"[{ep}/{epochs}] train {tr:.4f} | val {vl:.4f} | acc {acc:.3%}\")\n",
        "        if acc > best:\n",
        "            torch.save(model.state_dict(), \"best.pt\")\n",
        "            best = acc\n",
        "    print(\"✓ training done, best.pt saved to /kaggle/working/\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument(\"--epochs\", type=int, default=4)\n",
        "    p.add_argument(\"--bs\",     type=int, default=32)\n",
        "    p.add_argument(\"--lr\",     type=float, default=3e-4)\n",
        "    args = p.parse_args()\n",
        "    main(args.epochs, args.bs, args.lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGyGOJ2Xf8w4",
        "outputId": "62fb2159-e13b-4c25-9e52-af32bf207860"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --epochs 20 --bs 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5hP4fNsgD-a",
        "outputId": "25a24c8c-dba6-450a-fe73-a285532db145"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/20] train 0.6300 | val 0.6984 | acc 74.451%\n",
            "[2/20] train 0.2777 | val 0.4836 | acc 83.566%\n",
            "[3/20] train 0.2062 | val 0.5583 | acc 80.506%\n",
            "[4/20] train 0.1687 | val 0.6125 | acc 77.645%\n",
            "[5/20] train 0.1246 | val 0.4486 | acc 85.096%\n",
            "[6/20] train 0.0982 | val 0.4298 | acc 86.693%\n",
            "[7/20] train 0.0862 | val 0.4477 | acc 86.494%\n",
            "[8/20] train 0.0717 | val 0.4259 | acc 87.558%\n",
            "[9/20] train 0.0621 | val 0.3964 | acc 88.290%\n",
            "[10/20] train 0.0424 | val 0.3906 | acc 89.288%\n",
            "[11/20] train 0.0433 | val 0.4697 | acc 87.891%\n",
            "[12/20] train 0.0328 | val 0.4097 | acc 89.820%\n",
            "[13/20] train 0.0197 | val 0.3591 | acc 89.687%\n",
            "[14/20] train 0.0191 | val 0.4076 | acc 89.754%\n",
            "[15/20] train 0.0173 | val 0.3994 | acc 89.820%\n",
            "[16/20] train 0.0134 | val 0.3950 | acc 89.887%\n",
            "[17/20] train 0.0134 | val 0.3995 | acc 90.086%\n",
            "[18/20] train 0.0166 | val 0.3903 | acc 90.818%\n",
            "[19/20] train 0.0078 | val 0.4044 | acc 90.752%\n",
            "[20/20] train 0.0117 | val 0.4042 | acc 89.953%\n",
            "✓ training done, best.pt saved to /kaggle/working/\n"
          ]
        }
      ]
    }
  ]
}